
Validation sanity check:   0%|                                                                    | 0/2 [00:00<?, ?it/s]
  | Name  | Type        | Params
--------------------------------------
0 | model | PeopleModel | 7.5 M
--------------------------------------
7.5 M     Trainable params
0         Non-trainable params
7.5 M     Total params
30.079    Total estimated model params size (MB)
Traceback (most recent call last):
  File "/mnt/f/people-model2/train.py", line 56, in <module>
    main("config/pm.yaml")
  File "/mnt/f/people-model2/train.py", line 53, in main
    trainer.fit(model_module, dataloader.train_dataloader(), dataloader.val_dataloader())
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1194, in _run
    self._dispatch()
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1306, in _run_train
    self._run_sanity_check(self.lightning_module)
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1370, in _run_sanity_check
    self._evaluation_loop.run()
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 110, in advance
    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 122, in advance
    output = self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 217, in _evaluation_step
    output = self.trainer.accelerator.validation_step(step_kwargs)
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/accelerators/accelerator.py", line 236, in validation_step
    return self.training_type_plugin.validation_step(*step_kwargs.values())
  File "/home/raymondliuth/.local/lib/python3.10/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 219, in validation_step
    return self.model.validation_step(*args, **kwargs)
  File "/mnt/f/people-model2/pm_experiment.py", line 65, in validation_step
    val_acc = self.model.mlm_accuracy(batch, outputs)
  File "/mnt/f/people-model2/people_model/model.py", line 104, in mlm_accuracy
    corrects = np.equal(relevent_predictions, relevent_targets)
  File "/home/raymondliuth/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/_tensor.py", line 1030, in __array__
    return self.numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.